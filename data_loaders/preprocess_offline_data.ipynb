{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdab7991-fc52-4c29-ac19-3754e31e45fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, pickle\n",
    "from kLLMmeans import get_embeddings, summarize_cluster\n",
    "from experiment_utils import load_dataset\n",
    "\n",
    "file_path = \"../kLLMmeans.py\"  # Adjust path as needed\n",
    "spec = importlib.util.spec_from_file_location(\"kLLMmeans\", file_path)\n",
    "kLLMmeans = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(kLLMmeans)\n",
    "\n",
    "file_path = \"../experiment_utils.py\"  # Adjust path as needed\n",
    "spec2 = importlib.util.spec_from_file_location(\"experiment_utils\", file_path)\n",
    "experiment_utils = importlib.util.module_from_spec(spec2)\n",
    "spec2.loader.exec_module(experiment_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee54e8f7-f1d0-44d7-9c96-4c21f3e89175",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = ['massive_D', 'massive_I', 'goemo', 'bank77', 'clinic']\n",
    "\n",
    "for data in data_type:\n",
    "    \n",
    "    data_dict = {}\n",
    "    print(data)\n",
    "    \n",
    "    labels, documents, num_clusters, prompt, text_type, instructor_prompt = experiment_utils.load_dataset(data, opt=data[-1])\n",
    "    embeddings = {}\n",
    "    for emb_type in ['distilbert', 'openai', 'e5-large', 'sbert']:\n",
    "        print(emb_type)\n",
    "        embeddings[emb_type] = kLLMmeans.get_embeddings(documents, emb_type=emb_type, instructor_prompt = \"\")\n",
    "    data_dict = {}\n",
    "    data_dict['data'] = data\n",
    "    data_dict['labels'] = labels\n",
    "    data_dict['num_clusters'] = num_clusters\n",
    "    data_dict['documents'] = documents\n",
    "    data_dict['embeddings'] = embeddings\n",
    "    data_dict['prompt'] = prompt\n",
    "    data_dict['text_type'] = text_type\n",
    "        \n",
    "    with open(\"../processed_data/data_\" + data + \".pkl\", \"wb\") as f:\n",
    "        pickle.dump(data_dict, f)\n",
    "\n",
    "    sentences_dict = {}\n",
    "    \n",
    "    for emb_type in ['distilbert', 'openai', 'e5-large', 'sbert']:\n",
    "        print(emb_type)\n",
    "        sents, index_map = build_sentence_corpus(documents)\n",
    "        X, _ = embed_sentences(sents, emb_type = emb_type)\n",
    "        text_sentences = {i: [] for i in range(len(documents))}\n",
    "        for i in range(len(sents)):\n",
    "            cur_index = index_map[i][0]\n",
    "            text_sentences[cur_index].append([sents[i],X[i]])\n",
    "        sentences_dict[emb_type] = text_sentences\n",
    "        \n",
    "        with open(\"../processed_data/data_sentences_\" + data + \".pkl\", \"wb\") as f:\n",
    "            pickle.dump(sentences_dict, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
